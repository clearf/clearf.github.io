---
title: "Managing Catastrophic Risk in a Dynamic World"
subtitle: "A Reading List"
layout: research
author: "System Logic Staff" 
description: "Practical resources and curated readings for managers and executives seeking to understand and reduce exposure
to major risks."
category: research
tags: [complexity,technology] 
permalink: 
pdf_path: "https://s3.amazonaws.com/content.system-logic.com/Reading+List--Managing+Catastrophic+Risk+in+a+Dynamic+World.pdf"
css:
  - resources.css
---

<div id="resources-content" class="resources">
	<p class="intro">
		System Logic’s mission is to help organizations reduce their exposure to the potentially catastrophic risks that stem from 		the interaction of human, organizational, and systemic vulnerabilities.
	</p>
	<p class="intro">
		We do this in two independent and parallel ways. We develop customized training for leaders and teams on decision making, 		biases, and risk. The trainings provide practical techniques that can be used both to manage risk and to make better 			decisions. 	Research shows that these techniques not only reduce risks but can also foster agile organizations and 				encourage innovation.
	</p>
	<p class="intro">
		In addition, we use a proprietary, research-based methodology to help managers identify hidden risks within their 				organizations. We then leverage the organization’s own risk-management expertise to formulate actionable mitigation 			strategies. 
	</p>
	<p class="intro">
		The following reading list introduces leaders to practical advice that they can use to overcome common human, 					organizational, and systemic challenges. While based on rigorous research, most of the following articles are 					specifically targeted to practitioners. As much as possible, we have chosen content that is open and accessible. 				Finally, we have included a selection of works that delve into the root causes of catastrophic failures so that 				interested readers may engage with the ideas that have inspired our own practice.  
	</p>
	<p class="summary-action">
		Should you wish to discuss training or implementation strategies for any of the ideas covered below, we would love to 			help. Get in touch by email or phone. (<a href="mailto:contact@system-logic.com">contact@system-logic.com<script cf-hash="f9e31" type="text/javascript">
/* <![CDATA[ */!function(){try{var t="currentScript"in document?document.currentScript:function(){for(var t=document.getElementsByTagName("script"),e=t.length;e--;)if(t[e].getAttribute("cf-hash"))return t[e]}();if(t&&t.previousSibling){var e,r,n,i,c=t.previousSibling,a=c.getAttribute("data-cfemail");if(a){for(e="",r=parseInt(a.substr(0,2),16),n=2;a.length-n;n+=2)i=parseInt(a.substr(n,2),16)^r,e+=String.fromCharCode(i);e=document.createTextNode(e),c.parentNode.replaceChild(e,c)}}}catch(u){}}();/* ]]> */</script></a>, 646-543-4250). 
	</p>
	<h2>I. Managing to Avoid Biases</h2>
		<p>
			Cognitive biases–fundamental limitations in human thinking–can result in decisions that are systematically and 					predictably flawed. These readings help leaders understand how to recognize and overcome the biases that teams and 				individuals bring to the table.
		</p>

	<p class="subhead">
		A 12-question checklist that can reveal the cognitive biases in teams
	</p>
	<p>
		Kahneman, D., D. Lovallo, and O. Sibony. 2011. <a href="http://bit.ly/1Ql9hN7">Before you Make that Big Decision.</a> <i>Harvard Business Review</i>, 89(6):50-60.
	</p>
	<p class="subhead">
		The premortem: A technique to unearth hidden risks
	</p>
	<p>
		Klein, G. 2007. <a href="http://bit.ly/1JdPc9z">Performing a Project Premortem.</a> <i>Harvard Business Review</i>, 85 (9): 18-19.
	</p>
	<p class="subhead">
		Six common mistakes to avoid when thinking about risk in organizations
	</p>
	<p>
		Taleb, N. N., D. G. Goldstein, and M. W. Spitznagel. 2009. <a href="http://bit.ly/1JdPhKC">The Six Mistakes Executives Make in Risk Management.</a> <i>Harvard Business Review</i>, 87(10): 78-81. 
	</p>
	<h2>II. Building Resilient Systems and Organizations</h2>
		<p>
			The way a system is built and the way an organization is structured can profoundly affect how resilient each is to 				unexpected shocks. From the role of redundant technology to the benefits of communication and learning from failures, 			these articles and books explore how a considered  approach to systemic and organizational features can increase 				robustness. 
		</p>

		<p class="subhead">
			Build a better mousetrap: how to design a resilient technology platform for your organization
		</p>
	<p>
    <a href="http://bit.ly/1yRzEVw">Black Swan in the Server Room: Avoiding Disaster in Disaster Planning.</a> 
        System Logic White Paper, 2014. 
	</p>
	<p class="subhead">
		Overcome overregulation in finance
	</p>
	<p>
		Clearfield, C., Tilcsik, A., and Berman, B. 2015. <a href="http://bit.ly/1OfBaI7">Preventing Crashes: 
            Lessons for the SEC from the Airline Industry.</a> <i>Harvard Kennedy School Review</i>. 
	</p>
		<p class="subhead">
		Predict the future: how to foresee the next catastrophe
	</p>
	<p>
    Watkins, M. D., and M. H. Bazerman. 2003. <a href="http://bit.ly/1yRyUzv">
        Predictable Surprises: The Disasters You Should Have Seen Coming.</a> 
    <i>Harvard Business Review</i>, 81(3): 72- 85. 
	</p>
		<p class="subhead">
		How paying attention to failure can pay dividends
		</p>
	<p>
		Tinsley, C. H., R. L. Dillon, and P. M. Madsen. 2011. <a href="http://bit.ly/1HWqPf7">How to Avoid Catastrophe.</a> <i>Harvard Business Review</i>, 89(4): 90-97.
	</p>
		<p class="subhead">
		Building resilient organizations that effectively manage unexpected crises
		</p>
	<p>
		Weick, K. E., & Sutcliffe, K. M. 2007. <a href="http://amzn.to/1JvMR6A">
            <i>Managing the Unexpected: Resilient Performance in an Age of Uncertainty.</i></a> John Wiley & Sons. 
	</p>
	<h2>III. The Big Picture: The Root Causes of Catastrophic Failure</h2>
		<p>
			The root causes of catastrophic failure are human, systemic, and organizational. These works go beyond applications 			relevant for practitioners. They provide in-depth case studies and lay the theoretical foundation for many of the 				insights on systemic failures that form the basis of our work.  
		</p>

	
		<p class="subhead">
			A systemic view: The role of complex interactions and tight coupling
			</p>
	<p>
		Perrow, C. 2011. <a href="http://amzn.to/1JdQQrK"><i>Normal Accidents: Living with High Risk Technologies.</i></a> 
            Princeton University Press. 
	</p>
		<p class="subhead">
			What can mountain climbing teach us about air crashes and nuclear meltdowns?
		</p>
	<p>
		Roberto, M. A. 2002. <a href="http://bit.ly/1HWshOw">Lessons from Everest: The Interaction of Cognitive Bias, 
            Psychological Safety, and System Complexity.</a> <i>California Management Review</i>, 45(1): 136-158. 
	</p>
		<p class="subhead">
			Ideas in Practice: A tour of the nuclear weapons “sausage factory”
		</p>
	<p>
		Schlosser, E. 2013. <a href="http://amzn.to/1OfHb7q"><i>Command and Control: Nuclear Weapons, the Damascus Accident, and the Illusion of Safety.</i></a> Penguin Group US.  
	</p>
		<p class="subhead">
			How small errors combine into major catastrophes
		</p>
	<p>
		Weick, K. E. 1990. <a href="http://bit.ly/1OI6tpR">The Vulnerable System: An Analysis of the Tenerife Air Disaster.</a>
            <i>Journal of Management</i>, 16(3):571-593. 
	</p>
</div>
