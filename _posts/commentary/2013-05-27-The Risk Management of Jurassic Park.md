---
title: "Dinosaurs and Risk Management"
layout: post
author: "Chris Clearfield" 
tags: [dynamics,coupling,criticality] 
permalink: 
redirect_from: "/commentary/posts/Dinosaurs and Risk Management177t/"
---

![image alt text](/assets/images/The Risk Management of Jurassic Park_images/image_0.png)

*Jurassic Park*, Spielberg's classic movie about a wildlife preserve full of cloned dinosaurs, was recently theatrically re-released in 3D. Though the dinosaurs now occupy the third dimension, the park’s risk management still falls flat. Complexity is the source of the risks at the center of the movie, as Ian Malcolm, an outside expert brought in to assess Jurassic Park’s vulnerabilities, argues. I agree with Malcolm, and in this post I examine the risk management blunders that contributed to the park’s failures. 

In Jurassic Park, power, security, and transportation are all tightly connected and centrally controlled. When the park’s power and security are turned off because of a rogue employee, the electric cars that guide the visitors are also brought to a stop and are no longer protected by the now-deactivated electric fences. This integration and centralized controls mean that the park is vulnerable to a single point of failure, and the park’s systems are too easy to put into an inoperative unsafe state. A robust design would recognize the critical nature of the park’s infrastructure and institute physical, software, and cultural barriers to accidentally or intentionally placing the park into an unsafe state. 

Embedded in this design flaw is a failure of communication and organizational checks and balances. A single programer, Dennis Nedry, implemented the majority of the park’s critical technology systems, and he turns out to be a nefarious actor--the dinosaur park equivalent of a "rogue trader"--who deliberately sabotaged the park’s systems for his own gain. Facilitating this sabotage is an organizational culture that lacks code review and a design review process. No other employee understands how his code works or has given input on critical design decisions. Such reviews resist the concentration of knowledge and make designs more robust to both intentional sabotage and the (far more likely) occurrence of unexpected failure. It is hard to catch a rogue actor and make a robust system when teams do not communicate about the myriad implementation choice that they are making.

In contrast to the park’s security systems, there *are* checks and balances built into the engineered biology of the dinosaurs. The dinosaurs are bred with two inherent controls: they are a single-sex population, and they lack the ability to synthesize the enzyme lysine, making them dependent on supply from the park for survival. While these seem like effective controls, biological systems are inherently very complicated and dynamic. Selective pressure--in the form of a competitive environment that rewards success--can create a winner-take-all model, where small differences in fitness (like a mutation that allows for the production of lysine) leads to a large difference in the ability for members that have the mutation to survive. When amplified through reproduction (some of the dinosaurs spontaneously change sex), such a mutation will be spread to the whole population as only the dinosaurs that synthesize lysine can survive without supplements. This manifests itself when it is discovered that the dinosaurs are breeding. 

In addition to the fragmented communication described above, the park lacks design and organizational skepticism. The extensive use of automation in the park, which removes a human’s judgment and ability to intervene, indicates trust in the "elegance of design." For example, the driverless cars are cutting edge (“No expense was spared,” chirps the park’s founder, Hammond). However, they are totally dependent on all systems working. A skeptical design would have emphasized the potential for failure and allowed for manual control and a battery or internal-combustion backup. Additionally, when the complex security system has been disabled, no remaining employee understands how to fix it. Perhaps a simple switch for the electric fences would have saved the day. 

From an organizational perspective, outside opinions are sought too late in the park’s construction, when it is already poised to open. At that stage, *status quo bias* is unavoidable. "Should we open this park that we have built," elicits a very different cognitive stance than the preemptive question: “should we build this park.” Decision makers are more likely to affirm the status quo than radically change directions, even in the face of new evidence that questions the wisdom of past decisions. Status quo bias’s cousin, the sunk-cost fallacy, makes it hard for organizations to walk away from a project they have already invested time and money in. Thus, even well-informed expert dissent (Both from outside experts and team members that understand the details of a project. ) is too easy to discard. Fortunately for Jurassic Park, the failure is so obvious that even the founder acknowledges that the project should be halted. If only every team had a *Tyrannosaurus rex* to unleash on failing projects. 

Contributing to the cultural and system design failures is the lack of engagement from upper management. The park’s charismatic and visionary founder, John Hammond, totally delegates the implementation and management of the critical systems to subordinates. On the information technology side, he ignores the important design choices being made. Rather, Hammond’s treats the programming staff as a cost center who just needs to "get it done." Trusted subordinates with expert knowledge are critical to effectively building any technology. So to is the ability for managers to understand their design choices and to nurture the robust design of critical systems by allowing space for discussion, disagreement, and skepticism. 

Better management could have made Jurassic Park more robust and prevented its failure. There were warning signs, like the death of a worker, that the park was unstable. A culture of communication and skepticism and a recognition of the inherent risks of the complex system could have avoided optimistic design decisions and learned from the warning signs and inevitable near-misses that did occur. Real-world complex systems like oil rigs, nuclear power plants, and fracking operations have clear parallels with Jurassic Park. But more broadly, there is a clear link between management challenges and operations that affect businesses competing in today’s fast moving, competitive environment. Even with the cost of a movie ticket today, a careful viewing of *Jurassic Park* is a cheap way for managers to learn, practically firsthand, from the failure of a complex system. And in 3D, no less. 

***[Chris Clearfield](http://www.system-logic.com/team/)** is a principal at [System Logic](http://www.system-logic.com), an independent consulting firm that focuses on issues of risk and complexity.* 

